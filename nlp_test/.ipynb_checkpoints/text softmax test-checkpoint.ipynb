{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../5-0. FastText/train_corpus.txt', delimiter='\\t', names=['label', 'words'])\n",
    "test_data = pd.read_csv('../5-0. FastText/test_corpus.txt', delimiter='\\t', names=['label', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    seq_len = 0\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for idx, w in enumerate(data.words.values):\n",
    "        w = str(w).strip().split(' ')\n",
    "        row = []\n",
    "        for i in w:\n",
    "            si = i.split('_')\n",
    "            if len(si) == 2 and si[1][0] not in ['S','J','U']:\n",
    "#             if len(si) == 2 and si[1][0] == 'N':\n",
    "                row.append(i.replace('+','_'))\n",
    "        if len(row):\n",
    "            cnt = len(row)\n",
    "            if seq_len < cnt:\n",
    "                seq_len = cnt\n",
    "            x_data.append(' '.join(row))\n",
    "            label = data.label.values[idx]\n",
    "            y_data.insert(0, [1,0] if label == '__label__P' else [0,1])\n",
    "            \n",
    "    return seq_len, x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len, train_x, train_y = preprocess(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, test_x, test_y = preprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = train_x[:50000]\n",
    "train_y = train_y[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = list(vocab_processor.fit_transform(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x = list(vocab_processor.fit_transform(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_dict = vocab_processor.vocabulary_._mapping\n",
    "word_index = sorted(vocab_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 84)\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_x).shape)\n",
    "print(np.array(train_y).shape)\n",
    "# print(np.array(test_x).shape)\n",
    "# print(np.array(test_y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, np.array(train_x).shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, np.array(train_y).shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.get_variable('W1', [np.array(train_x).shape[1], 60], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W2 = tf.get_variable('W2', [60, 60], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W3 = tf.get_variable('W3', [60, np.array(train_y).shape[1]], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B1 = tf.Variable(tf.random_normal([60]))\n",
    "# B2 = tf.Variable(tf.random_normal([60]))\n",
    "B3 = tf.Variable(tf.random_normal([np.array(train_y).shape[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L1 = tf.nn.relu(tf.matmul(X, W1)+B1)\n",
    "# L1 = tf.nn.dropout(L1, 0.5)\n",
    "\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, W2)+B2)\n",
    "# L2 = tf.nn.dropout(L2, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_H = tf.matmul(L1, W3)+B3\n",
    "H = tf.nn.softmax(_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# C = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=H, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_H, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = tf.train.AdamOptimizer(0.1).minimize(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P = tf.equal(\n",
    "#     tf.cast(H > 0.5, tf.float32),\n",
    "#     tf.cast(Y > 0.5, tf.float32)\n",
    "# )\n",
    "# A = tf.reduce_mean(tf.cast(P, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = tf.equal(\n",
    "    tf.argmax(H, 1),\n",
    "    tf.argmax(Y, 1),\n",
    ")\n",
    "A = tf.reduce_mean(tf.cast(P, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(500):\n",
    "    _, c = sess.run([T, C], feed_dict={X: train_x, Y: train_y})\n",
    "#     _, c = sess.run([T, C], feed_dict={X: test_x, Y: test_y})\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sess.run(A, feed_dict={X: test_x, Y: test_y})\n",
    "print(\n",
    "    '{0} %'.format(a)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid = ' '.join(['{}_{}'.format(word, tag).replace('+','_') for word, tag in mecab.pos('재미없는 영화였어')])\n",
    "print(valid)\n",
    "\n",
    "valid = list(vocab_processor.fit_transform([valid]))\n",
    "print(valid)\n",
    "\n",
    "# tf.arg_max(H, 1)\n",
    "\n",
    "h = sess.run(H, feed_dict={X: valid})\n",
    "print(h)\n",
    "print(np.argmax(h, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
