{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../5-0. FastText/train_corpus.txt', delimiter='\\t', names=['label', 'words'])\n",
    "test_data = pd.read_csv('../5-0. FastText/test_corpus.txt', delimiter='\\t', names=['label', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    seq_len = 0\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for idx, w in enumerate(data.words.values):\n",
    "        w = str(w).strip().split(' ')\n",
    "        row = []\n",
    "        for i in w:\n",
    "            si = i.split('_')\n",
    "#             if len(si) == 2 and si[1][0] not in ['S','J','U']:\n",
    "            if len(si) == 2 and si[1][0] in ['N']:\n",
    "                row.append(i.replace('+','_'))\n",
    "        if len(row):\n",
    "            cnt = len(row)\n",
    "            if seq_len < cnt:\n",
    "                seq_len = cnt\n",
    "            x_data.append(' '.join(row))\n",
    "            label = data.label.values[idx]\n",
    "            y_data.insert(0, [1,0] if label == '__label__P' else [0,1])\n",
    "            \n",
    "    return seq_len, x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len, train_x, train_y = preprocess(train_data)\n",
    "_, test_x, test_y = preprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(seq_len)\n",
    "\n",
    "train_x = list(vocab_processor.fit_transform(train_x))\n",
    "test_x = list(vocab_processor.fit_transform(test_x))\n",
    "\n",
    "vocab_dict = vocab_processor.vocabulary_._mapping\n",
    "word_index = sorted(vocab_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141656, 66)\n",
      "(141656, 2)\n",
      "(27, 66)\n",
      "(27, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_x).shape)\n",
    "print(np.array(train_y).shape)\n",
    "print(np.array(test_x).shape)\n",
    "print(np.array(test_y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = train_x[:500]\n",
    "train_y = train_y[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33200\n"
     ]
    }
   ],
   "source": [
    "input_length = np.array(train_x).shape[1]\n",
    "output_length = 2\n",
    "words_count = len(word_index)\n",
    "level_count = 2\n",
    "filters = [3,4,5]\n",
    "filters_length = 128\n",
    "\n",
    "print(words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, input_length])\n",
    "Y = tf.placeholder(tf.float32, [None, output_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Tensor(\"embedding/Variable/read:0\", shape=(33200, 2), dtype=float32)\n",
      "embed.shape: (?, 66, 2)\n",
      "embed_char.shape: (?, 66, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"embedding\"):    \n",
    "    W = tf.Variable(tf.random_uniform([words_count, level_count], -1., 1.))\n",
    "    print('W:',W)\n",
    "\n",
    "    embed = tf.nn.embedding_lookup(W, X)\n",
    "    print('embed.shape:',embed.shape)\n",
    "    \n",
    "    embed_char = tf.expand_dims(embed, -1)\n",
    "    print('embed_char.shape:',embed_char.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 128]\n",
      "[1, 64, 1, 1] \n",
      "\n",
      "[4, 2, 1, 128]\n",
      "[1, 63, 1, 1] \n",
      "\n",
      "[5, 2, 1, 128]\n",
      "[1, 62, 1, 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pooled = []\n",
    "\n",
    "for _, f_no in enumerate(filters):\n",
    "    with tf.name_scope(\"conv-maxpool-%s\" % f_no):\n",
    "        \n",
    "        filter_shape = [f_no, level_count, 1, filters_length]\n",
    "        \n",
    "        print(filter_shape)\n",
    "        print([1,input_length-f_no+1,1,1],'\\n')\n",
    "        \n",
    "        W = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                filter_shape, stddev=0.1\n",
    "            ), name='W'\n",
    "        )\n",
    "        b = tf.Variable(\n",
    "            tf.constant(0.1, shape=[filters_length]), name='b'\n",
    "        )\n",
    "        \n",
    "        conv = tf.nn.conv2d(\n",
    "            embed_char,\n",
    "            W,\n",
    "            strides=[1,1,1,1], padding='VALID',\n",
    "            name='conv'\n",
    "        )\n",
    "        \n",
    "        h = tf.nn.relu(tf.nn.bias_add(conv, b), name='relu')\n",
    "        \n",
    "        ksize=[1,input_length-f_no+1,1,1]\n",
    "        \n",
    "        pool = tf.nn.max_pool(\n",
    "            h,\n",
    "            ksize=ksize,\n",
    "            strides=[1,1,1,1], padding='VALID',\n",
    "            name='pool'\n",
    "        )\n",
    "        pooled.append(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_filters_total = filters_length * len(filters)\n",
    "num_filters_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'conv-maxpool-3/pool:0' shape=(?, 1, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv-maxpool-4/pool:0' shape=(?, 1, 1, 128) dtype=float32>,\n",
       " <tf.Tensor 'conv-maxpool-5/pool:0' shape=(?, 1, 1, 128) dtype=float32>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, 1, 1, 384) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = tf.concat(axis=3, values=pooled)\n",
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 384) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_flat = tf.reshape(pool, [-1, num_filters_total])\n",
    "pool_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout/dropout/mul:0' shape=(?, 384) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope(\"dropout\"):\n",
    "    pool_drop = tf.nn.dropout(pool_flat, 0.5)\n",
    "pool_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384, 2]\n"
     ]
    }
   ],
   "source": [
    "print([num_filters_total, output_length])\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    W = tf.get_variable(\n",
    "        'W', \n",
    "        shape=[num_filters_total, output_length],\n",
    "        initializer=tf.contrib.layers.xavier_initializer()\n",
    "    )\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_length]), name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"scores:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "    score = tf.nn.xw_plus_b(pool_drop, W, b, name='scores')\n",
    "    print(score)\n",
    "    predictions = tf.argmax(score, 1)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=score, labels=Y)\n",
    "    )\n",
    "    \n",
    "    T = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_predictions = tf.equal(predictions, tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718022\n",
      "0.05021\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(500):\n",
    "    _, c = sess.run([T, loss], feed_dict={X : train_x, Y: train_y})\n",
    "    if epoch %100 == 0:\n",
    "        print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44444445]\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "a = sess.run([accuracy], feed_dict={X: test_x, Y: test_y})\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋_VA 은_ETM 영화_NNG\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vocab_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cf6aadb75339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_processor' is not defined"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "valid = ' '.join(['{}_{}'.format(word, tag).replace('+','_') for word, tag in mecab.pos('좋은 영화')])\n",
    "print(valid)\n",
    "\n",
    "valid = list(vocab_processor.fit_transform([valid]))\n",
    "print(valid)\n",
    "\n",
    "# tf.arg_max(H, 1)\n",
    "\n",
    "h = sess.run([score], feed_dict={X: valid})\n",
    "print(h)\n",
    "print(np.argmax(h,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
